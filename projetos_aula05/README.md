# Aula 5 – Processamento de Dados em Larga Escala com Python

Este repositório corresponde à **Aula 5 da formação em Ciência de Dados**, onde exploramos na prática técnicas avançadas de processamento de grandes volumes de dados utilizando Python e bibliotecas de alto desempenho.

## 📌 Projeto Desenvolvido

Durante esta aula, desenvolvemos o seguinte projeto:

### [Um Bilhão de Linhas: Desafio de Processamento de Dados com Python](https://github.com/Rafasansouza/desafio-1-bilhao-linhas-python)

> 📁 *Clique no link acima para acessar o projeto completo.*

O desafio consistiu em processar um arquivo com **1 bilhão de linhas (~14GB)** contendo medições de temperatura em estações meteorológicas. O objetivo foi calcular estatísticas como **mínimo, média e máximo** por estação, e comparar a performance entre diferentes bibliotecas como:

- Python puro
- Pandas
- Dask
- Polars
- DuckDB

## 📚 Conceitos Abordados

- Processamento de arquivos massivos
- Estratégias de leitura eficiente em Python
- Cálculo de estatísticas agregadas
- Comparação de desempenho entre diferentes engines
- Otimizações com DuckDB, Polars e Dask
- Benchmarking e análise de performance

## 📦 Tecnologias e Ferramentas

- Python 3.12.1
- Poetry
- DuckDB
- Polars
- Dask
- Pandas
- Bash + awk (extra)

## 🚀 Resultado

Este projeto mostrou como bibliotecas como **DuckDB** e **Polars** podem ser significativamente mais rápidas e eficientes no processamento de grandes volumes de dados, além de requererem menos código em comparação com abordagens tradicionais.

---

📁 *Você pode conferir o código-fonte, instruções de execução e resultados completos no repositório principal do projeto clicando no link acima.*

